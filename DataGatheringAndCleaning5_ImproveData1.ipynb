{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "print(\"Importing names to test for improvement... \")\n",
    "names = pandas.read_csv(\"data/names_cat.csv\", usecols=[\"name\", \"n_publs\", \"likely_gender\", \"score\", \"clean_name\", \"first_name\", \"last_name\", \"likely_gender_2\", \"score_2\", \"gender_dif\", \"score_dif\"])\n",
    "print(\"Names imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index & accessing cells: https://pythonhow.com/accessing-dataframe-columns-rows-and-cells/\n",
    "names = names.set_index(\"name\", drop = False)\n",
    "print(names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting private key... \")\n",
    "# Get private API Key for NamSor API v2 (contained in txt file)\n",
    "key = ''\n",
    "\n",
    "# Import personal key\n",
    "with open(\"key.txt\", \"r\") as file:\n",
    "    key = file.read()\n",
    "\n",
    "if(len(key) > 0):\n",
    "    print(\"Got private key.\")\n",
    "else: \n",
    "    print(\"Could not find private key. Please check the file name and make sure you have an API key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up NamSor API v2 to get the gender of a name\n",
    "# https://www.namsor.com/\n",
    "# https://v2.namsor.com/NamSorAPIv2/apidoc.html\n",
    "# using NamSor API v2 Python SDK\n",
    "# https://github.com/namsor/namsor-python-sdk2\n",
    "# licensed under GNU Affero General Public License v3.0\n",
    "\n",
    "# Following script partly taken from https://github.com/namsor/namsor-python-sdk2 \"Getting Started\" \n",
    "# and adapted to keep key private and remove unnecessary lines.\n",
    "\n",
    "print(\"Setting up NamSor API v2 connection settings...\")\n",
    "\n",
    "import openapi_client\n",
    "from openapi_client.rest import ApiException\n",
    "\n",
    "# Configure API key authorization: api_key\n",
    "configuration = openapi_client.Configuration()\n",
    "configuration.api_key['X-API-KEY'] = key\n",
    "# create an instance of the API class\n",
    "pers_api_instance = openapi_client.PersonalApi(openapi_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_consider = names.copy()\n",
    "print(\"Will be parsing and reconsidering {} names.\".format(len(names_to_consider)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the names using the API's models\n",
    "def createPersonalNameIn(name_entry):\n",
    "    return openapi_client.PersonalNameIn(id=name_entry['name'], name=name_entry['clean_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now parsing the full names into first and last name, sending in\n",
    "# one batch at a time and saving the result answer by answer.\n",
    "# If the API calling gets interrupted:\n",
    "# 1. check that no names got lost: ((len(names_to_consider)-len(result)) == len(names_stack))\n",
    "# 2. If True: Restart only the code in the while loop.\n",
    "\n",
    "batch_size = 1000 #1000 is the API limit given by NamSor\n",
    "start = 0\n",
    "end = batch_size\n",
    "result = []\n",
    "\n",
    "names_stack = names_to_consider[['name', 'clean_name']].to_dict('records')\n",
    "\n",
    "print(names_stack[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''while (len(names_stack) >= batch_size):\n",
    "    try:\n",
    "        current_batch = list(map(createPersonalNameIn, names_stack[start:end])) # create batch of names in correct format\n",
    "        batch_personal_name_in = openapi_client.BatchPersonalNameIn(personal_names=current_batch) # convert batch to correct format\n",
    "        api_response = pers_api_instance.parse_name_batch(batch_personal_name_in=batch_personal_name_in) # call API\n",
    "        result = result + api_response.personal_names # save result\n",
    "        \n",
    "        del names_stack[start:end] # delete the names that have already been categorized from the stack\n",
    "        \n",
    "        # categorize remaining names if they are less than a batch size\n",
    "        if(len(names_stack) < batch_size and len(names_stack) > 0):\n",
    "            current_batch = list(map(createPersonalNameIn, names_stack)) # create the batch of remaining names\n",
    "            batch_personal_name_in = openapi_client.BatchPersonalNameIn(personal_names=current_batch)\n",
    "            api_response = pers_api_instance.parse_name_batch(batch_personal_name_in=batch_personal_name_in)\n",
    "            result = result + api_response.personal_names\n",
    "            names_stack = [] # empty the stack\n",
    "        \n",
    "        print(\"Batch of names analyzed\")\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling PersonalApi: gender_full_batch: %s\\n\" % e)\n",
    "\n",
    "\n",
    "print(\"All batches analyzed.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the names using the API's models\n",
    "import math\n",
    "\n",
    "def createParsedPersonalNameIn(names_entry):\n",
    "    if(names_entry['first_name'] is None or names_entry['last_name'] is None):\n",
    "        return None\n",
    "    return openapi_client.FirstLastNameIn(id=names_entry['name'], first_name=names_entry['first_name'], last_name=names_entry['last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now parsing the full names into first and last name, sending in\n",
    "# one batch at a time and saving the result answer by answer.\n",
    "# If the API calling gets interrupted:\n",
    "# 1. check that no names got lost: ((len(names_to_consider)-len(result)) == len(names_stack))\n",
    "# 2. If True: Restart only the code in the while loop.\n",
    "\n",
    "batch_size = 1000 #1000 is the API limit given by NamSor\n",
    "start = 0\n",
    "end = batch_size\n",
    "result = []\n",
    "\n",
    "names_stack = list(names_to_consider[['name', 'first_name', 'last_name']].to_dict('records'))\n",
    "names_stack = list(filter(lambda x: x['first_name'] is not None and x['last_name'] is not None, names_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call API to find out gender but ALSO pass info on country/origin\n",
    "'''while (len(names_stack) >= batch_size):\n",
    "    try:\n",
    "        current_batch = list(map(createParsedPersonalNameIn, names_stack[start:end])) # create batch of names in correct format\n",
    "        batch_first_last_name_in = openapi_client.BatchFirstLastNameIn(personal_names=current_batch) # convert batch to correct format\n",
    "        api_response = pers_api_instance.gender_batch(batch_first_last_name_in=batch_first_last_name_in) # call API\n",
    "        result = result + api_response.personal_names # save result\n",
    "        \n",
    "        del names_stack[start:end] # delete the names that have already been categorized from the stack\n",
    "        \n",
    "        # categorize remaining names if they are less than a batch size\n",
    "        if(len(names_stack) < batch_size and len(names_stack) > 0):\n",
    "            current_batch = list(map(createParsedPersonalNameIn, names_stack)) # create the batch of remaining names\n",
    "            batch_first_last_name_in = openapi_client.BatchFirstLastNameIn(personal_names=current_batch)\n",
    "            api_response = pers_api_instance.gender_batch(batch_first_last_name_in=batch_first_last_name_in)\n",
    "            result = result + api_response.personal_names\n",
    "            names_stack = [] # empty the stack\n",
    "        \n",
    "        print(\"Batch of names analyzed\")\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling PersonalApi: gender_full_batch: %s\\n\" % e)\n",
    "\n",
    "if(len(names_stack) != 0):\n",
    "    try:\n",
    "        current_batch = list(map(createParsedPersonalNameIn, names_stack)) # create the batch of remaining names\n",
    "        batch_first_last_name_in = openapi_client.BatchFirstLastNameIn(personal_names=current_batch)\n",
    "        api_response = pers_api_instance.gender_batch(batch_first_last_name_in=batch_first_last_name_in)\n",
    "        result = result + api_response.personal_names\n",
    "        names_stack = [] # empty the stack\n",
    "        \n",
    "        print(\"Batch of names analyzed\")\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling PersonalApi: gender_full_batch: %s\\n\" % e)\n",
    "\n",
    "print(\"All batches analyzed. Returned {} results.\".format(len(results)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results (list of openapi_client.models.personal_name_gendered_out.PersonalNameGenderedOut) to (list of dictionaries)\n",
    "print('Filling the results into the names dataframe...')\n",
    "for oapi_el in result:\n",
    "    names_to_consider.at[oapi_el.id, 'likely_gender_3'] = oapi_el.likely_gender\n",
    "    names_to_consider.at[oapi_el.id, 'score_3'] = round(oapi_el.score)\n",
    "    gender_dif = (names_to_consider.at[oapi_el.id, 'likely_gender'] != names_to_consider.at[oapi_el.id, 'likely_gender_3'])\n",
    "    if (gender_dif):\n",
    "        g_val = 1\n",
    "    names_to_consider.at[oapi_el.id, 'gender_dif_2'] = gender_dif\n",
    "    names_to_consider.at[oapi_el.id, 'score_dif_2'] = (names_to_consider.at[oapi_el.id, 'score_3'] - names_to_consider.at[oapi_el.id, 'score'])\n",
    "\n",
    "print('Dataframe completed with API results. Here is a sample: {}'.format(names_to_consider[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving test names...\")\n",
    "names_to_consider.to_csv(\"data/names_improvement_test.csv\")\n",
    "print(\"Test names saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x=names_to_consider['gender_dif_2'], y=names_to_consider['score_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_consider['score_3'].hist(bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_consider['score'].hist(bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_consider['score_dif_2'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_by_score_dif = names_to_consider.groupby(['score_dif_2', 'gender_dif_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_by_score_dif = names_by_score_dif.agg({'score':'count'}) # score just counts how many entries there are per score_dif and gender_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diffs = list(map(lambda x: x[0], names_by_score_dif.index.values))\n",
    "gender_diffs = list(map(lambda x: x[1], names_by_score_dif.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=score_diffs, y=names_by_score_dif['score'], c=gender_diffs, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_statistics_improved_names_sample2 = names_to_consider.describe()\n",
    "descriptive_statistics_improved_names_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving test names...\")\n",
    "descriptive_statistics_improved_names_sample2.to_csv(\"data/names_improvement_test_statistics.csv\")\n",
    "print(\"Test names saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_changed = names_to_consider[names_to_consider['gender_dif_2'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_changed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_changed_more_certain = gender_changed[gender_changed['score_dif_2'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_changed_more_certain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_improved = names_to_consider[names_to_consider['score_dif_2'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_improved.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gender assumption changed for only 100 of 1000 entries \n",
    "# (assuming the gender change is valid if the new score is higher than the old score, which is the case in 44 cases)\n",
    "\n",
    "# The score improves on average by 0.48 with a std of 1.21. \n",
    "# The mean improvement is 0, the 25% quartile is 0, the 75% quartile is 1.\n",
    "# The score is at maximum improved by 7 and in the worst case decreased by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
