{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "print(\"Importing categorized names... \")\n",
    "names = pandas.read_csv(\"data/names_cat.csv\", usecols=[\"name\", \"n_publs\", \"likely_gender\", \"score\"])\n",
    "print(\"Names imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index & accessing cells: https://pythonhow.com/accessing-dataframe-columns-rows-and-cells/\n",
    "names = names.set_index(\"name\", drop = False)\n",
    "print(names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the names and categorize all with a score of <= 2 as (likely_gender=)uncategorizable. \n",
    "# Count how many names these are\n",
    "# If it's an okay-number, also sort out all with a score of 2<score<=3\n",
    "# Will Asian names need to be handled separately, or names with one letter? Or is the score categorization sufficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From describe we can see that at least 25% of names have a score of 2 or less. \n",
    "# At least 50% have a score of at leat 4 (median). \n",
    "# The minimum score is 0 (as expected), the maximum score is 33. \n",
    "# the mean is almost 5 with a std of 3.5\n",
    "\n",
    "# Some more info we get from describe about the number of publications:\n",
    "# On average, a person publishes 5.7 pieces (with a std of 18!)\n",
    "# The record for most publications was set with 1694 pieces, wow!\n",
    "# At least 25% of authors published at least 1 piece,\n",
    "# At least 50% published at least 2 pieces (median),\n",
    "# At least 75% published at least 4 pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names[names['score'] >= 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1359955 / len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getting all names with a score lower than or equal 2 we found out: \n",
    "# 160377 names have a score of 0\n",
    "# 233923 names have a score of 1\n",
    "# 280557 names have a score of 2\n",
    "# Overall, 674857 names have a score lower or equal 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "# Grouping and aggregating: https://stackoverflow.com/questions/40480744/pandas-group-by-and-count\n",
    "n_publs_by_score = names.groupby(\"score\").agg({'n_publs':'sum'})\n",
    "n_publs_by_score = n_publs_by_score.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_authors_by_score = names.groupby(\"score\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# float to int: https://stackoverflow.com/questions/6569528/python-float-to-int-conversion\n",
    "bins = names['score'].max() / 3\n",
    "bins = int(round(bins))\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_score_0 = names['score'].hist(bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_publs_0_max_10 = names[names['n_publs']<=10]['n_publs'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_publs_0 = names['n_publs'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_publs_by_score.index.values, n_publs_by_score['n_publs'], 'b', label='Amount of publications by score')\n",
    "plt.plot(n_authors_by_score.index.values, n_authors_by_score.values, 'g', label='Amount of authors by score')\n",
    "plt.plot([3, 3], [0, n_publs_by_score['n_publs'].max()], 'r-', lw=2, label=\"Score = 3\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_publs_by_score.index.values, n_publs_by_score['n_publs'], 'b_', label='Amount of publications by score')\n",
    "plt.plot(n_authors_by_score.index.values, n_authors_by_score.values, 'g_', label='Amount of authors by score')\n",
    "plt.plot([3, 3], [0, n_publs_by_score['n_publs'].max()], 'r-', lw=2, label=\"Score = 3\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(n_publs_by_score.index.values, n_publs_by_score['n_publs'], label='Amount of publications by score', alpha=0.5, color='b')\n",
    "plt.bar(n_authors_by_score.index.values, n_authors_by_score.values, label='Amount of authors by score', alpha=0.5, color='g')\n",
    "plt.plot([3, 3], [0, n_publs_by_score['n_publs'].max()], 'r-', lw=2, label=\"Score = 3\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first name and last name from full name with NamSor\n",
    "# Calculate the gender + score for the full name for those names with a score less than 7\n",
    "# Save the new result (gender and score) in the df\n",
    "# Compare the results. \n",
    "# To test if this makes sense: \n",
    "# Get sample of names with score less than 7\n",
    "# send to api\n",
    "# save results\n",
    "# row: gender changed?: bool\n",
    "# how much score changed?: int\n",
    "# plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
